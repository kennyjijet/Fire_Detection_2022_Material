{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar0Q0aX7-Im6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54199549-8d78-492e-f9d0-757f6f1b47a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            " 1.jpg\n",
            " 8.jpg\n",
            "'Another Jerusalem Miracle - 26May2022 abridged.docx'\n",
            "'Colab Notebooks'\n",
            " darknet\n",
            " Dataset\n",
            " Dataset1\n",
            " imagepro\n",
            " Image_processing\n",
            " KT_Colab\n",
            "'Loss and Redemption - 6 April .docx'\n",
            " MR2DX-LegendCup-CDlist-Offset-Calculator.xlsx\n",
            "'My Drive'\n",
            " Sample_YoloV3.zip\n",
            " Tensorflow\n",
            " Thesis\n",
            " train_yolov3_custom.ipynb\n",
            " video1624940358.mp4\n",
            " Wedding_plan\n",
            " week_19video1083996781.mp4\n",
            " Weights\n",
            "TEST\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Make numpy values easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive\n",
        "print('TEST')\n",
        "# https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE#scrollTo=q2Jjv0yRKLPe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLOvWp7AmucM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e118907d-f8d5-4ede-da44-57c159696abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting minepy\n",
            "  Downloading minepy-1.2.6.tar.gz (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from minepy) (1.21.6)\n",
            "Building wheels for collected packages: minepy\n",
            "  Building wheel for minepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minepy: filename=minepy-1.2.6-cp37-cp37m-linux_x86_64.whl size=177569 sha256=4e90fd3b47aba55739d4551da61e6e03ea0c23ca9d18d740f17476a4083c574e\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/71/75/403a33428e468a25c93fa7b672d070b304f36642eb699a29e0\n",
            "Successfully built minepy\n",
            "Installing collected packages: minepy\n",
            "Successfully installed minepy-1.2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mine\n",
            "  Downloading mine-1.8.post2-py3-none-any.whl (26 kB)\n",
            "Collecting psutil<3.0,>=2.1\n",
            "  Downloading psutil-2.2.1.tar.gz (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting minilog<0.4,>=0.3\n",
            "  Downloading minilog-0.3.1-py3-none-any.whl (8.9 kB)\n",
            "Collecting crayons<0.2.0,>=0.1.2\n",
            "  Downloading crayons-0.1.2.tar.gz (3.2 kB)\n",
            "Collecting YORM<2.0,>=1.4\n",
            "  Downloading YORM-1.6.2-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting PyYAML<6,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting simplejson~=3.8\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting parse~=1.8.0\n",
            "  Downloading parse-1.8.4.tar.gz (30 kB)\n",
            "Collecting pathlib2!=2.3.3\n",
            "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2!=2.3.3->YORM<2.0,>=1.4->mine) (1.15.0)\n",
            "Building wheels for collected packages: crayons, psutil, parse\n",
            "  Building wheel for crayons (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crayons: filename=crayons-0.1.2-py3-none-any.whl size=3126 sha256=7f2b0a4e66b7122575ddc3f482a663e5d4f975c9cc0a16987dc6a856cac6b677\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/61/a6/05a19534c5fbccb0116083cf84b0c452fc1b5f6aeb0b2e8bf0\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-2.2.1-cp37-cp37m-linux_x86_64.whl size=97520 sha256=2ced623fb662059b09b8f53460779201f19bf64d08166992aefdcca63fca185a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/7e/a1/eef895eba31fa12d59d5754e03a5e93cd18ba23ea83b051833\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.8.4-py3-none-any.whl size=21123 sha256=94f743248b9b6f0353eecc3a150e0d88dd06b895c426bfa4cb1cdc0394108e6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/7b/8e/eeeab7a3715df5f1957a32e2e1cfe708192663ddfd367bcdfe\n",
            "Successfully built crayons psutil parse\n",
            "Installing collected packages: simplejson, PyYAML, pathlib2, parse, colorama, YORM, psutil, minilog, crayons, mine\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 1.25.3 requires psutil>=5.0, but you have psutil 2.2.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-5.4.1 YORM-1.6.2 colorama-0.4.5 crayons-0.1.2 mine-1.8.post2 minilog-0.3.1 parse-1.8.4 pathlib2-2.3.7.post1 psutil-2.2.1 simplejson-3.17.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install minepy\n",
        "!pip install mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjAdOCLWLTzt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "features_col_name = [\"iVecCoun\",\t\n",
        "                     \"dRadius\",\t\n",
        "                     \"dCohIndex\",\t\n",
        "                     \"vardRadius\",\t\n",
        "                     \"vardCohIndex\",\t\n",
        "                     \"d_varRad\",\t\n",
        "                     \"d_varCoh\",\t\n",
        "                     \"da5Radius_v0\",\t\n",
        "                     \"da5Radius_v1\",\t\n",
        "                     \"da5Radius_v2\",\t\n",
        "                     \"da5Radius_v3\",\t\n",
        "                     \"da5Radius_v4\",\t\n",
        "                     \"da5Radius_f0\",\t\n",
        "                     \"da5Radius_f1\",\t\n",
        "                     \"da5Radius_f2\",\t\n",
        "                     \"da5Radius_f3\",\t\n",
        "                     \"da5Radius_f4\",\t\n",
        "                     \"da5Radius_%0\",\t\n",
        "                     \"da5Radius_%1\",\t\n",
        "                     \"da5Radius_%2\",\t\n",
        "                     \"da5Radius_%3\",\t\n",
        "                     \"da5Radius_%4\",\t\n",
        "                     \"dCos\",\t\n",
        "                     \"dSin\",\t\n",
        "                     \"da5Degree_v0\",\t\n",
        "                     \"da5Degree_v1\",\t\n",
        "                     \"da5Degree_v2\",\t\n",
        "                     \"da5Degree_v3\",\t\n",
        "                     \"da5Degree_v4\",\t\n",
        "                     \"da5Degree_f0\",\t\n",
        "                     \"da5Degree_f1\",\t\n",
        "                     \"da5Degree_f2\",\t\n",
        "                     \"da5Degree_f3\",\t\n",
        "                     \"da5Degree_f4\",\t\n",
        "                     \"da5Degree_%0\",\t\n",
        "                     \"da5Degree_%1\",\t\n",
        "                     \"da5Degree_%2\",\t\n",
        "                     \"da5Degree_%3\",\t\n",
        "                     \"da5Degree_%4\",\t\n",
        "                     \"iRGBTotal\",\t\n",
        "                     \"iRMean\",\t\n",
        "                     \"iGMean\",\t\n",
        "                     \"iBMean\",\t\n",
        "                     \"d_luminance\",\t\n",
        "                     \"ia5R_v0\",\t\n",
        "                     \"ia5R_v1\",\t\n",
        "                     \"ia5R_v2\",\t\n",
        "                     \"ia5R_v3\",\t\n",
        "                     \"ia5R_v4\",\t\n",
        "                     \"ia5R_f0\",\t\n",
        "                     \"ia5R_f1\",\t\n",
        "                     \"ia5R_f2\",\t\n",
        "                     \"ia5R_f3\",\t\n",
        "                     \"ia5R_f4\",\t\n",
        "                     \"ia5R_%0\",\t\n",
        "                     \"ia5R_%1\",\t\n",
        "                     \"ia5R_%2\",\t\n",
        "                     \"ia5R_%3\",\t\n",
        "                     \"ia5R_%4\",\t\n",
        "                     \"ia5G_v0\",\t\n",
        "                     \"ia5G_v1\",\t\n",
        "                     \"ia5G_v2\",\t\n",
        "                     \"ia5G_v3\",\t\n",
        "                     \"ia5G_v4\",\t\n",
        "                     \"ia5G_f0\",\t\n",
        "                     \"ia5G_f1\",\t\n",
        "                     \"ia5G_f2\",\t\n",
        "                     \"ia5G_f3\",\t\n",
        "                     \"ia5G_f4\",\t\n",
        "                     \"ia5G_%0\",\t\n",
        "                     \"ia5G_%1\",\t\n",
        "                     \"ia5G_%2\",\t\n",
        "                     \"ia5G_%3\",\t\n",
        "                     \"ia5G_%4\",\t\n",
        "                     \"ia5B_v0\",\t\n",
        "                     \"ia5B_v1\",\t\n",
        "                     \"ia5B_v2\",\t\n",
        "                     \"ia5B_v3\",\n",
        "                     \"ia5B_v4\",\t\n",
        "                     \"ia5B_f0\",\t\n",
        "                     \"ia5B_f1\",\t\n",
        "                     \"ia5B_f2\",\t\n",
        "                     \"ia5B_f3\",\t\n",
        "                     \"ia5B_f4\",\t\n",
        "                     \"ia5B_%0\",\t\n",
        "                     \"ia5B_%1\",\t\n",
        "                     \"ia5B_%2\",\t\n",
        "                     \"ia5B_%3\",\t\n",
        "                     \"ia5B_%4\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0YGaap2r-sm"
      },
      "outputs": [],
      "source": [
        "def get_train_data(data):\n",
        "    train_data = []\n",
        "    train_label = []\n",
        "    for k in data:\n",
        "        for j in data[k]:\n",
        "          train_data.append(j)\n",
        "          train_label.append(int(k))\n",
        "    return train_data, train_label\n",
        "\n",
        "def get_test_data(data):\n",
        "    test_data = []\n",
        "    test_label = []\n",
        "    for k in data:\n",
        "        for j in data[k]:\n",
        "          test_data.append(j)\n",
        "          test_label.append(int(k))\n",
        "    return test_data, test_label\n",
        "\n",
        "def get_Data(dir_name=\"\", remove=list()):\n",
        "    data={}\n",
        "    for index,name in enumerate(os.listdir(dir_name)):\n",
        "        if \".csv\" in name:\n",
        "            with open(dir_name+\"/\"+name,'r') as f:\n",
        "                d=f.readline().strip()\n",
        "                d=f.readline().strip()\n",
        "                while d:\n",
        "                    line=d.split()\n",
        "                    label=line[0]\n",
        "                    if label not in data:\n",
        "                        data[label]=[]\n",
        "                    raw_data=line[1:]\n",
        "                    raw_data=np.delete(raw_data, remove, axis=0)\n",
        "                    one_data=[]\n",
        "                    for i in raw_data:\n",
        "                        # if not i.replace('.','').isdigit():\n",
        "                            # i=0\n",
        "                        one_data.append(float(i))\n",
        "                    data[label].append(one_data)\n",
        "                    d=f.readline().strip()\n",
        "            f.close()\n",
        "    return data\n",
        "\n",
        "def count_accuracy(y,pred_y):\n",
        "    correct = 0.\n",
        "    for k in range(len(y)):\n",
        "        if pred_y[k] == y[k]:\n",
        "            correct += 1\n",
        "    return correct/len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi1LI2fpEI7m"
      },
      "outputs": [],
      "source": [
        "# Import your necessary dependencies\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from yellowbrick.model_selection import RFECV\n",
        "from yellowbrick.datasets import load_credit\n",
        "\n",
        "\n",
        "def get_score_features_random_forest_classifier(dir_name, remove):\n",
        "  data = get_Data(dir_name, remove)\n",
        "  test_data, test_label = get_test_data(data)\n",
        "  fit_ranking = []\n",
        "  # Feature extraction\n",
        "  \"\"\"\n",
        "  Use the Recursive Feature Elimination algorithm in order to fit the data into the classification function \n",
        "  and know how many features I need to select so that its accuracy is high. \n",
        "  Use Stratified Cross Validation to enhance the accuracy.\n",
        "  A model can be random forests.\n",
        "  \"\"\"\n",
        "  model = RandomForestClassifier(n_estimators=100,random_state=True,n_jobs=-1)\n",
        "  rfe = RFE(model)\n",
        "  fit = rfe.fit(test_data, test_label)\n",
        "  print(\"Num Features: %s\" % (fit.n_features_))\n",
        "  print(\"Selected Features: %s\" % (fit.support_))\n",
        "  print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
        "\n",
        "  # Mapping\n",
        "  for i in range(len(features_col_name)):\n",
        "    fit_ranking.append(fit.ranking_[i])\n",
        "  return fit_ranking\n",
        "\n",
        "\n",
        "def display_RFE(dir_name, remove):\n",
        "  data = get_Data(dir_name, remove)\n",
        "  test_data, test_label = get_test_data(data)\n",
        "  cv = StratifiedKFold(2)\n",
        "  visualizer = RFECV(RandomForestClassifier(), cv=cv, scoring='f1_weighted')\n",
        "  visualizer.fit(test_data, test_label)        # Fit the data to the visualizer\n",
        "  visualizer.show()           # Finalize and render the figure\n",
        "  return\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKKWA_vbe3dF"
      },
      "outputs": [],
      "source": [
        "# Code from Second MIC\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Algorithms\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "from minepy import MINE\n",
        "\n",
        "def get_score_features(dir_name, remove, mic_threshold):\n",
        "  good_features = []\n",
        "  print(\"dir_name:\", dir_name)\n",
        "  tolal_features = 89 - len(remove)\n",
        "  data = get_Data(dir_name, remove)\n",
        "  print(data)\n",
        "  print(data[\"0\"])\n",
        "  print(data[\"1\"])\n",
        "  d0=np.transpose(data[\"0\"]) # transpose the matrix that each row stand for each feature\n",
        "  d1=np.transpose(data[\"1\"])\n",
        "  print(data)\n",
        "  mine = MINE(alpha=0.6, c=15)\n",
        "  mic_matrix = np.zeros(tolal_features)\n",
        "  print(mic_matrix)\n",
        "  for i in range(tolal_features):\n",
        "    c=list(d0[i])+list(d1[i])\n",
        "    d=[0.]*len(d0[i])+[1.]*len(d1[i])\n",
        "    mine.compute_score(c, d) # computer the mic between feature and label\n",
        "    # mic_matrix[i] = mine.mic()\n",
        "    # print(mine.mic())\n",
        "    # print(mine.get_score())\n",
        "    mic_matrix[i] = mine.mic()\n",
        "    if mic_matrix[i] > mic_threshold and i not in remove:\n",
        "      good_features.append(mic_matrix[i])\n",
        "  print(\"good_features\", good_features)\n",
        "  print(\"len(good_features)\", len(good_features))\n",
        "  print(\"finish.\")\n",
        "  return good_features\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# All attributes\n",
        "rf_ref = []\n",
        "mic = []\n",
        "path_datasets = \"Datasets\"\n",
        "rf_ref = get_score_features_random_forest_classifier(\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, [])\n",
        "mic = get_score_features(\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, [], 0.0)"
      ],
      "metadata": {
        "id": "fyoACsr_xr_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plot\n",
        "# Get x values of the sine wave\n",
        "plot.figure(figsize = (20, 8))\n",
        "\n",
        "# data to be plotted\n",
        "x = np.arange(0, len(mic))\n",
        "y = mic\n",
        "\n",
        "# Plot a sine wave using time and amplitude obtained for the sine wave\n",
        "plot.plot(x, y, 'o')\n",
        "\n",
        "# Give a title for the sine wave plot\n",
        "plot.title('MIC')\n",
        "\n",
        "# Give x axis label for the sine wave plot\n",
        "plot.xlabel('Feature indexes')\n",
        "\n",
        "# Give y axis label for the sine wave plot\n",
        "plot.ylabel('MIC results')\n",
        "plot.grid(True, which='both')\n",
        "plot.axhline(y=0, color='k')\n",
        "plot.show()\n",
        "\n",
        "\n",
        "plot.figure(figsize = (20, 8))\n",
        "# data to be plotted\n",
        "x = np.arange(0, len(rf_ref))\n",
        "y = rf_ref\n",
        "\n",
        "# Plot a sine wave using time and amplitude obtained for the sine wave\n",
        "plot.plot(x, y, 'o')\n",
        "\n",
        "# Give a title for the sine wave plot\n",
        "plot.title('RF-RFE')\n",
        "\n",
        "# Give x axis label for the sine wave plot\n",
        "plot.xlabel('Feature indexes')\n",
        "\n",
        "# Give y axis label for the sine wave plot\n",
        "plot.ylabel('RF-RFE results')\n",
        "plot.grid(True, which='both')\n",
        "plot.axhline(y=0, color='k')\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "EHiVm-R_nS7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision\n",
        "# creating a DataFrame\n",
        "dict = {'Features_col_name' : features_col_name,\n",
        "        'RFE' : rf_ref,\n",
        "        'MIC' : mic,\n",
        "}\n",
        "df = pd.DataFrame(dict)\n",
        "filtered_df = df\n",
        "display(filtered_df)"
      ],
      "metadata": {
        "id": "hxvkWvA90eay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# motion_model_random_forest = train_random_forest_fire('Datasets', [])\n",
        "# test_random_forest_fire(motion_model_random_forest, [])\n",
        "def generate_remove_array(remove_list):\n",
        "  all_features = [\n",
        "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
        "    11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19,\t20,\n",
        "    21, 22, 23, 24,\t25,\t26,\t27,\t28,\t29,\t30,\n",
        "    31,\t32,\t33,\t34,\t35,\t36,\t37,\t38,\t39,\t40,\n",
        "    41,\t42, 43,\t44,\t45,\t46,\t47,\t48,\t49,\t50,\n",
        "    51,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t60,\n",
        "    61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t70,\n",
        "    71,\t72,\t73, 74, 75, 76, 77, 78, 79, 80,\n",
        "    81, 82, 83, 84, 85, 86, 87, 88]\n",
        "  for ele in remove_list:\n",
        "    all_features.remove(ele)\n",
        "  return all_features\n",
        "\n",
        "\n",
        "selected_features_motion = []\n",
        "selected_features_luminance = []\n",
        "selected_features_colours_R = []\n",
        "selected_features_colours_G = []\n",
        "selected_features_colours_B = []\n",
        "\n",
        "# Motion\n",
        "motions_df = filtered_df[filtered_df.Features_col_name.isin([\n",
        "  \"iVecCoun\", \"dRadius\", \"dCohIndex\", \"vardRadius\", \"vardCohIndex\", \"dCos\", \"dSin\"])]\n",
        "display(motions_df)\n",
        "print('selected features', motions_df.index)\n",
        "selected_features_motion = motions_df.index.values\n",
        "\n",
        "# Luminance\n",
        "luminance_df = filtered_df[filtered_df.Features_col_name.isin([\"d_luminance\"])]\n",
        "display(luminance_df)\n",
        "print('selected features', luminance_df.index)\n",
        "selected_features_luminance = luminance_df.index.values\n",
        "\n",
        "# Colours_R\n",
        "colours_R_df = filtered_df[filtered_df.Features_col_name.isin([\n",
        "            \"ia5R_v0\", \"ia5R_v1\", \"ia5R_v2\", \"ia5R_v3\", \"ia5R_v4\",\n",
        "            \"ia5R_f0\", \"ia5R_f1\", \"ia5R_f2\", \"ia5R_f3\", \"ia5R_f4\"\n",
        "            ])]\n",
        "display(colours_R_df)\n",
        "print('selected features', colours_R_df.index)\n",
        "selected_features_colours_R = colours_R_df.index.values\n",
        "\n",
        "# Colours_G\n",
        "colours_G_df = filtered_df[filtered_df.Features_col_name.isin([\n",
        "            \"ia5G_v0\", \"ia5G_v1\", \"ia5G_v2\", \"ia5G_v3\", \"ia5G_v4\",\n",
        "            \"ia5G_f0\", \"ia5G_f1\", \"ia5G_f2\", \"ia5G_f3\", \"ia5G_f4\",\n",
        "            ])]\n",
        "display(colours_G_df)\n",
        "print('selected features', colours_G_df.index)\n",
        "selected_features_colours_G = colours_G_df.index.values\n",
        "\n",
        "# Colours_B\n",
        "colours_B_df = filtered_df[filtered_df.Features_col_name.isin([\n",
        "            \"ia5B_v0\", \"ia5B_v1\", \"ia5B_v2\", \"ia5B_v3\", \"ia5B_v4\",\n",
        "            \"ia5B_f0\", \"ia5B_f1\", \"ia5B_f2\", \"ia5B_f3\", \"ia5B_f4\",\n",
        "            ])]\n",
        "display(colours_B_df)\n",
        "print('selected features', colours_B_df.index)\n",
        "selected_features_colours_B = colours_B_df.index.values"
      ],
      "metadata": {
        "id": "MRlza35hiKjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# linear algebra\n",
        "import numpy as np \n",
        "\n",
        "# data processing\n",
        "import pandas as pd \n",
        "\n",
        "# data visualization\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "# Algorithms\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# https://towardsdatascience.com/fit-vs-predict-vs-fit-predict-in-python-scikit-learn-f15a34a8d39f\n",
        "path_datasets = \"Datasets\"\n",
        "def train_random_forest_fire(remove):\n",
        "    data_train = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, remove=remove)\n",
        "    train_data, train_label = get_train_data(data_train)\n",
        "    random_forest_model = RandomForestClassifier(\n",
        "        n_jobs=-1, max_depth=11, \n",
        "        n_estimators=50, min_samples_leaf=1)\n",
        "    # Split train and test\n",
        "    random_forest_model.fit(train_data, train_label)\n",
        "    return random_forest_model\n",
        "\n",
        "def train_decision_tree_fire(remove):\n",
        "    data_train = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, remove=remove)\n",
        "    train_data, train_label = get_train_data(data_train)\n",
        "    decision_tree_model = DecisionTreeClassifier()\n",
        "    decision_tree_model.fit(train_data, train_label)  \n",
        "    return decision_tree_model\n",
        "\n",
        "def train_KNN(remove):\n",
        "    data_train = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, remove=remove)\n",
        "    train_data, train_label = get_train_data(data_train)\n",
        "    knn_model = KNeighborsClassifier(n_neighbors = 3) \n",
        "    knn_model.fit(train_data, train_label)\n",
        "    return knn_model\n",
        "\n",
        "def train_logistic_regression(remove):\n",
        "    data_train = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, remove=remove)\n",
        "    train_data, train_label = get_train_data(data_train)\n",
        "    logreg_model = LogisticRegression()\n",
        "    logreg_model.fit(train_data, train_label)\n",
        "    return logreg_model\n",
        "\n",
        "def train_gaussian_naive_bayes(remove):\n",
        "    data_train = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, remove=remove)\n",
        "    train_data, train_label = get_train_data(data_train)\n",
        "    gaussian_model = GaussianNB()\n",
        "    gaussian_model.fit(train_data, train_label)\n",
        "    return gaussian_model\n",
        "\n",
        "def train_neural_network_mlpclassifier(remove):\n",
        "  data_train = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/\" + path_datasets, remove=remove)\n",
        "  train_data, train_label = get_train_data(data_train)\n",
        "  neural_network_mlp_model = MLPClassifier(random_state=1, max_iter=300)\n",
        "  neural_network_mlp_model.fit(train_data, train_label)\n",
        "  return neural_network_mlp_model\n",
        "\n",
        "\n",
        "motion_model_random_forest_all = train_random_forest_fire([])\n",
        "\n",
        "def generate_remove_array(remove_list):\n",
        "  all_features = [\n",
        "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
        "    11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19,\t20,\n",
        "    21, 22, 23, 24,\t25,\t26,\t27,\t28,\t29,\t30,\n",
        "    31,\t32,\t33,\t34,\t35,\t36,\t37,\t38,\t39,\t40,\n",
        "    41,\t42, 43,\t44,\t45,\t46,\t47,\t48,\t49,\t50,\n",
        "    51,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t60,\n",
        "    61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t70,\n",
        "    71,\t72,\t73, 74, 75, 76, 77, 78, 79, 80,\n",
        "    81, 82, 83, 84, 85, 86, 87, 88]\n",
        "  for ele in remove_list:\n",
        "    all_features.remove(ele)\n",
        "  return all_features\n",
        "\n",
        "# Use Remove to split up motion, luminance, and RGB\n",
        "# Get attributes for motion by removing others attribute.\n",
        "# Motion attributes 0,\t1,\t2,\t3,\t4, 22,\t23\n",
        "\n",
        "\"\"\"\n",
        "remove_not_motion = [\n",
        "                    5, 6,\t7,\t8,\t9,\t10,\n",
        "          11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19,\t20,\n",
        "          21, 24,\t25,\t26,\t27,\t28,\t29,\t30,\n",
        "          31,\t32,\t33,\t34,\t35,\t36,\t37,\t38,\t39,\t40,\n",
        "          41,\t42, 43,\t44,\t45,\t46,\t47,\t48,\t49,\t50,\n",
        "          51,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t60,\n",
        "          61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t70,\n",
        "          71,\t72,\t73, 74, 75, 76, 77, 78, 79, 80,\n",
        "          81, 82, 83, 84, 85, 86, 87, 88]\n",
        "\"\"\"\n",
        "\n",
        "remove_not_motion = generate_remove_array(selected_features_motion)\n",
        "print(remove_not_motion)\n",
        "motion_model_random_forest = train_random_forest_fire(remove_not_motion)\n",
        "\n",
        "# Get attributes for luminance by removing others attribute.\n",
        "# luminance attribute: 43.\n",
        "# ***** opaque, transparency.\n",
        "\"\"\"\n",
        "remove_not_luminance = [\n",
        "          0, 1,\t2,\t3,\t4, 5, 6,\t7,\t8,\t9,\t10,\t\n",
        "          11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19,\t20,\t\n",
        "          21, 22,\t23, 24,\t25,\t26,\t27,\t28,\t29,\t30,\t\n",
        "          31,\t32,\t33,\t34,\t35,\t36,\t37,\t38,\t39,\t40,\t\n",
        "          41,\t42,\t44,\t45,\t46,\t47,\t48,\t49,\t50,\t\n",
        "          51,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t60,\t\n",
        "          61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t70,\t\n",
        "          71,\t72,\t73, 74, 75, 76, 77, 78, 79, 80, \n",
        "          81, 82, 83, 84, 85, 86, 87, 88]\n",
        "\"\"\"\n",
        "remove_not_luminance = generate_remove_array(selected_features_luminance)\n",
        "print(remove_not_luminance)\n",
        "luminance_model_random_forest = train_random_forest_fire(remove_not_luminance)\n",
        "\n",
        "# Get attributes for R colour.\n",
        "# colour attribute: 44\t45\t46\t47\t48\t49\t50\t51\t52\t53\n",
        "\"\"\"\n",
        "remove_not_colour_R = [\n",
        "          0, 1,\t2,\t3,\t4, 5, 6,\t7,\t8,\t9,\t10,\t\n",
        "          11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19,\t20,\t\n",
        "          21, 22,\t23, 24,\t25,\t26,\t27,\t28,\t29,\t30,\t\n",
        "          31,\t32,\t33,\t34,\t35,\t36,\t37,\t38,\t39,\t40,\t\n",
        "          41,\t42,\t43, 54,\t55,\t56,\t57,\t58,\t59,\t60,\t\n",
        "          61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t70,\t\n",
        "          71,\t72,\t73,\t74,\t75,\t76,\t77,\t78,\t79,\t80,\t\n",
        "          81,\t82,\t83,\t84,\t85,\t86,\t87,\t88]\n",
        "\"\"\"\n",
        "remove_not_colour_R = generate_remove_array(selected_features_colours_R)\n",
        "print(remove_not_colour_R)\n",
        "colour_R_model_random_forest = train_random_forest_fire(remove_not_colour_R)\n",
        "\n",
        "# Get attributes for G colour.\n",
        "# colour attribute: 59\t60\t61\t62\t63\t64\t65\t66\t67\t68\n",
        "\"\"\"\n",
        "remove_not_colour_G = [\n",
        "          0, 1,\t2,\t3,\t4, 5, 6,\t7,\t8,\t9,\t10,\n",
        "          11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19,\t20,\t\n",
        "          21, 22,\t23, 24,\t25,\t26,\t27,\t28,\t29,\t30,\t\n",
        "          31,\t32,\t33,\t34,\t35,\t36,\t37,\t38,\t39,\t40,\t\n",
        "          41,\t42,\t43, 44, 45, 46, 47, 48, 49, 50,\n",
        "          51, 52, 53, 54, 55, 56, 57, 58, 69,\t70,\n",
        "          71,\t72,\t73,\t74,\t75,\t76,\t77,\t78,\t79,\t80,\t\n",
        "          81,\t82,\t83,\t84,\t85,\t86,\t87,\t88]\n",
        "\"\"\"\n",
        "remove_not_colour_G = generate_remove_array(selected_features_colours_G)\n",
        "print(remove_not_colour_G)\n",
        "colour_G_model_random_forest = train_random_forest_fire(remove_not_colour_G)\n",
        "\n",
        "# Get attributes for B colour.\n",
        "# colour attribute: 74\t75\t76\t77\t78\t79\t80\t81\t82\t83\n",
        "\"\"\"\n",
        "remove_not_colour_B = [\n",
        "          0, 1,\t2,\t3,\t4, 5, 6,\t7,\t8,\t9,\t10,\t\n",
        "          11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19,\t20,\t\n",
        "          21, 22,\t23, 24,\t25,\t26,\t27,\t28,\t29,\t30,\t\n",
        "          31,\t32,\t33,\t34,\t35,\t36,\t37,\t38,\t39,\t40,\t\n",
        "          41,\t42,\t43, 44, 45, 46, 47, 48, 49, 50,\n",
        "          51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
        "          61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
        "          71,\t72,\t73,\t84,\t85,\t86,\t87,\t88]\n",
        "\"\"\"\n",
        "remove_not_colour_B = generate_remove_array(selected_features_colours_B)\n",
        "print(remove_not_colour_B)\n",
        "colour_B_model_random_forest = train_random_forest_fire(remove_not_colour_B)\n",
        "print(\"Training done!\")\n"
      ],
      "metadata": {
        "id": "sTvRcpNMLISN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "import math\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def is_fire(model, remove, name=\"\", threshold = 80):\n",
        "    # SB_Vt = \"SB_19_Vt_0.1\"\n",
        "    # Comparison purple fire and smoke.\n",
        "    # data_test_fire = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/Dataset_test_fire_\" + SB_Vt, remove=remove)\n",
        "    # data_test_fire = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/Dataset_test_not_fire_\" + SB_Vt, remove=remove)\n",
        "    \n",
        "    # Test with blue fire.\n",
        "    footage_name = \"footage01-015\"\n",
        "    # Test with orange fire.\n",
        "    # footage_name = \"footage01-010\"\n",
        "    # Test with non fire.\n",
        "    # footage_name = \"footage02-023\"\n",
        "\n",
        "    # footage_name = \"footage01-014\"\n",
        "    # footage_name = \"footage00-008\"\n",
        "    # footage_name = \"footage02-006\"\n",
        "\n",
        "    data_test_fire = get_Data(dir_name=\"/content/gdrive/MyDrive/Tensorflow/second/Test_datasets/\" + footage_name, remove=remove)\n",
        "    test_data, test_label = get_test_data(data_test_fire)\n",
        "    Y_prediction = model.predict(test_data)\n",
        "    isFire = True if ((100 * np.count_nonzero(Y_prediction == 1) / len(Y_prediction)) > threshold) else False\n",
        "    percentage_fire = (100 * np.count_nonzero(Y_prediction == 1) / len(Y_prediction))\n",
        "    percentage_not_fire = (100 * np.count_nonzero(Y_prediction == 0) / len(Y_prediction))\n",
        "    df = pd.DataFrame({\n",
        "      name : [str(percentage_not_fire) + \" %\", str(percentage_fire) + \" %\"],\n",
        "    })\n",
        "    print(tabulate(df, headers='keys', tablefmt='psql'))\n",
        "    return isFire, percentage_fire, percentage_not_fire;\n",
        "\n",
        "def print_report(nameOfReport, motion_model, luminance_model, colour_R_model, colour_G_model, colour_B_model, \n",
        "                 remove_not_motion, remove_not_luminance, remove_not_colour_R, remove_not_colour_G, remove_not_colour_B):\n",
        "  print(nameOfReport)\n",
        "  isMotionOfFire, percentage_fire_motion, percentage_not_fire_motion = is_fire(motion_model, remove_not_motion, \"Motion\", 80)\n",
        "  isLuminanceOfFire, percentage_fire_luminance, percentage_not_fire_luminance = is_fire(luminance_model, remove_not_luminance, \"Luminance\", 50)\n",
        "  isColourOfFireR, percentage_fire_R, percentage_not_fire_R = is_fire(colour_R_model, remove_not_colour_R, \"Red Channel\", 80)\n",
        "  isColourOfFireG, percentage_fire_G, percentage_not_fire_G = is_fire(colour_G_model, remove_not_colour_G, \"Green Channel\", 20)\n",
        "  isColourOfFireB, percentage_fire_B, percentage_not_fire_B = is_fire(colour_B_model, remove_not_colour_B, \"Blue Channel\", 80)\n",
        "\n",
        "  motion.append(percentage_fire_motion)\n",
        "  motion.append(percentage_not_fire_motion)\n",
        "  \n",
        "  luminance.append(percentage_fire_luminance)\n",
        "  luminance.append(percentage_not_fire_luminance)\n",
        "  \n",
        "  red.append(percentage_fire_R)\n",
        "  red.append(percentage_not_fire_R)\n",
        "  \n",
        "  green.append(percentage_fire_G)\n",
        "  green.append(percentage_not_fire_G)\n",
        "  \n",
        "  blue.append(percentage_fire_B)\n",
        "  blue.append(percentage_not_fire_B)\n",
        "\n",
        "  print(\"IsMotionOfFire fire:\", isMotionOfFire)\n",
        "  print(\"isLuminanceOfFire fire:\", isLuminanceOfFire)\n",
        "  print(\"isColouredOfFireR fire:\", isColourOfFireR)\n",
        "  print(\"isColouredOfFireG fire:\", isColourOfFireG)\n",
        "  print(\"isColouredOfFireB fire:\", isColourOfFireB)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "_y6yysgmKMRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motion = []\n",
        "luminance = []\n",
        "red = []\n",
        "green = []\n",
        "blue = []\n",
        "all = []\n",
        "\n",
        "allIsFire, allPercentage_fire, allPercentage_not_fire= is_fire(motion_model_random_forest_all, [], \"All\", 0)\n",
        "\n",
        "print_report(\"Random forest\",\n",
        "             motion_model_random_forest, \n",
        "             luminance_model_random_forest, \n",
        "             colour_R_model_random_forest, \n",
        "             colour_G_model_random_forest,\n",
        "             colour_B_model_random_forest,\n",
        "             remove_not_motion,\n",
        "             remove_not_luminance,\n",
        "             remove_not_colour_R,\n",
        "             remove_not_colour_G,\n",
        "             remove_not_colour_B)"
      ],
      "metadata": {
        "id": "XVBsuxAZMbiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "# set width of bar\n",
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(20, 8))\n",
        " \n",
        "# set height of bar\n",
        "Fire = [motion[0], luminance[0], red[0], green[0], blue[0]]\n",
        "Not_Fire = [motion[1], luminance[1], red[1], green[1], blue[1]]\n",
        "\n",
        "# Set position of bar on X axis\n",
        "br1 = np.arange(len(Fire))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "\n",
        "# Make the plot\n",
        "plt.bar(br1, Fire, color ='red', width = barWidth,\n",
        "        edgecolor ='grey', label ='Fire')\n",
        "plt.bar(br2, Not_Fire, color ='green', width = barWidth,\n",
        "        edgecolor ='grey', label ='Not Fire')\n",
        " \n",
        "# Adding Xticks\n",
        "plt.xlabel('', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('', fontweight ='bold', fontsize = 15)\n",
        "plt.xticks([r + 0.12 for r in range(len(Fire))],\n",
        "        ['Motion', 'Luminance', 'Red', 'Green', 'Blue'])\n",
        " \n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MmwilSlfZ_tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALL features\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "# set width of bar\n",
        "barWidth = 0.5\n",
        "fig = plt.subplots(figsize =(5, 8))\n",
        " \n",
        "# set height of bar\n",
        "Fire = [allPercentage_fire]\n",
        "Not_Fire = [allPercentage_not_fire]\n",
        "\n",
        "# Set position of bar on X axis\n",
        "br1 = np.arange(len(Fire))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "\n",
        "# Make the plot\n",
        "plt.bar(br1, Fire, color ='red', width = barWidth,\n",
        "        edgecolor ='grey', label ='Fire')\n",
        "plt.bar(br2, Not_Fire, color ='green', width = barWidth,\n",
        "        edgecolor ='grey', label ='Not Fire')\n",
        " \n",
        "# Adding Xticks\n",
        "plt.xlabel('', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('', fontweight ='bold', fontsize = 15)\n",
        "plt.xticks([r + 0.25 for r in range(len(Fire))],\n",
        "        ['All 89 Features'])\n",
        " \n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hkOsvBBfcSZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ACML_code_features_selection_and_fire_detection_stages.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}