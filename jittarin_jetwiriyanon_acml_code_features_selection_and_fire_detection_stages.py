# -*- coding: utf-8 -*-
"""ACML_code_features_selection_and_fire_detection_stages.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/170IsP5fzTphjj4NW20gTxxOCyShpKNBj
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import pathlib
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Make numpy values easier to read.
np.set_printoptions(precision=3, suppress=True)

import tensorflow as tf
from tensorflow.keras import layers
import cv2
import matplotlib.pyplot as plt
import glob
from google.colab import drive
drive.mount('/content/gdrive')
!ln -s /content/gdrive/My\ Drive/ /mydrive
!ls /mydrive
print('TEST')
# https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE#scrollTo=q2Jjv0yRKLPe

!pip install minepy
!pip install mine

import os
features_col_name = ["iVecCoun",	
                     "dRadius",	
                     "dCohIndex",	
                     "vardRadius",	
                     "vardCohIndex",	
                     "d_varRad",	
                     "d_varCoh",	
                     "da5Radius_v0",	
                     "da5Radius_v1",	
                     "da5Radius_v2",	
                     "da5Radius_v3",	
                     "da5Radius_v4",	
                     "da5Radius_f0",	
                     "da5Radius_f1",	
                     "da5Radius_f2",	
                     "da5Radius_f3",	
                     "da5Radius_f4",	
                     "da5Radius_%0",	
                     "da5Radius_%1",	
                     "da5Radius_%2",	
                     "da5Radius_%3",	
                     "da5Radius_%4",	
                     "dCos",	
                     "dSin",	
                     "da5Degree_v0",	
                     "da5Degree_v1",	
                     "da5Degree_v2",	
                     "da5Degree_v3",	
                     "da5Degree_v4",	
                     "da5Degree_f0",	
                     "da5Degree_f1",	
                     "da5Degree_f2",	
                     "da5Degree_f3",	
                     "da5Degree_f4",	
                     "da5Degree_%0",	
                     "da5Degree_%1",	
                     "da5Degree_%2",	
                     "da5Degree_%3",	
                     "da5Degree_%4",	
                     "iRGBTotal",	
                     "iRMean",	
                     "iGMean",	
                     "iBMean",	
                     "d_luminance",	
                     "ia5R_v0",	
                     "ia5R_v1",	
                     "ia5R_v2",	
                     "ia5R_v3",	
                     "ia5R_v4",	
                     "ia5R_f0",	
                     "ia5R_f1",	
                     "ia5R_f2",	
                     "ia5R_f3",	
                     "ia5R_f4",	
                     "ia5R_%0",	
                     "ia5R_%1",	
                     "ia5R_%2",	
                     "ia5R_%3",	
                     "ia5R_%4",	
                     "ia5G_v0",	
                     "ia5G_v1",	
                     "ia5G_v2",	
                     "ia5G_v3",	
                     "ia5G_v4",	
                     "ia5G_f0",	
                     "ia5G_f1",	
                     "ia5G_f2",	
                     "ia5G_f3",	
                     "ia5G_f4",	
                     "ia5G_%0",	
                     "ia5G_%1",	
                     "ia5G_%2",	
                     "ia5G_%3",	
                     "ia5G_%4",	
                     "ia5B_v0",	
                     "ia5B_v1",	
                     "ia5B_v2",	
                     "ia5B_v3",
                     "ia5B_v4",	
                     "ia5B_f0",	
                     "ia5B_f1",	
                     "ia5B_f2",	
                     "ia5B_f3",	
                     "ia5B_f4",	
                     "ia5B_%0",	
                     "ia5B_%1",	
                     "ia5B_%2",	
                     "ia5B_%3",	
                     "ia5B_%4"]

def get_train_data(data):
    train_data = []
    train_label = []
    for k in data:
        for j in data[k]:
          train_data.append(j)
          train_label.append(int(k))
    return train_data, train_label

def get_test_data(data):
    test_data = []
    test_label = []
    for k in data:
        for j in data[k]:
          test_data.append(j)
          test_label.append(int(k))
    return test_data, test_label

def get_Data(dir_name="", remove=list()):
    data={}
    for index,name in enumerate(os.listdir(dir_name)):
        if ".csv" in name:
            with open(dir_name+"/"+name,'r') as f:
                d=f.readline().strip()
                d=f.readline().strip()
                while d:
                    line=d.split()
                    label=line[0]
                    if label not in data:
                        data[label]=[]
                    raw_data=line[1:]
                    raw_data=np.delete(raw_data, remove, axis=0)
                    one_data=[]
                    for i in raw_data:
                        # if not i.replace('.','').isdigit():
                            # i=0
                        one_data.append(float(i))
                    data[label].append(one_data)
                    d=f.readline().strip()
            f.close()
    return data

def count_accuracy(y,pred_y):
    correct = 0.
    for k in range(len(y)):
        if pred_y[k] == y[k]:
            correct += 1
    return correct/len(y)

# Import your necessary dependencies
# from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold

from yellowbrick.model_selection import RFECV
from yellowbrick.datasets import load_credit


def get_score_features_random_forest_classifier(dir_name, remove):
  data = get_Data(dir_name, remove)
  test_data, test_label = get_test_data(data)
  fit_ranking = []
  # Feature extraction
  """
  Use the Recursive Feature Elimination algorithm in order to fit the data into the classification function 
  and know how many features I need to select so that its accuracy is high. 
  Use Stratified Cross Validation to enhance the accuracy.
  A model can be random forests.
  """
  model = RandomForestClassifier(n_estimators=100,random_state=True,n_jobs=-1)
  rfe = RFE(model)
  fit = rfe.fit(test_data, test_label)
  print("Num Features: %s" % (fit.n_features_))
  print("Selected Features: %s" % (fit.support_))
  print("Feature Ranking: %s" % (fit.ranking_))

  # Mapping
  for i in range(len(features_col_name)):
    fit_ranking.append(fit.ranking_[i])
  return fit_ranking


def display_RFE(dir_name, remove):
  data = get_Data(dir_name, remove)
  test_data, test_label = get_test_data(data)
  cv = StratifiedKFold(2)
  visualizer = RFECV(RandomForestClassifier(), cv=cv, scoring='f1_weighted')
  visualizer.fit(test_data, test_label)        # Fit the data to the visualizer
  visualizer.show()           # Finalize and render the figure
  return

# Code from Second MIC
import numpy as np
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.feature_selection import RFE

# Algorithms
from sklearn import linear_model
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier

from sklearn import metrics
from minepy import MINE

def get_score_features(dir_name, remove, mic_threshold):
  good_features = []
  print("dir_name:", dir_name)
  tolal_features = 89 - len(remove)
  data = get_Data(dir_name, remove)
  print(data)
  print(data["0"])
  print(data["1"])
  d0=np.transpose(data["0"]) # transpose the matrix that each row stand for each feature
  d1=np.transpose(data["1"])
  print(data)
  mine = MINE(alpha=0.6, c=15)
  mic_matrix = np.zeros(tolal_features)
  print(mic_matrix)
  for i in range(tolal_features):
    c=list(d0[i])+list(d1[i])
    d=[0.]*len(d0[i])+[1.]*len(d1[i])
    mine.compute_score(c, d) # computer the mic between feature and label
    # mic_matrix[i] = mine.mic()
    # print(mine.mic())
    # print(mine.get_score())
    mic_matrix[i] = mine.mic()
    if mic_matrix[i] > mic_threshold and i not in remove:
      good_features.append(mic_matrix[i])
  print("good_features", good_features)
  print("len(good_features)", len(good_features))
  print("finish.")
  return good_features

from mpl_toolkits.mplot3d import Axes3D 
import matplotlib.pyplot as plt
import numpy as np

# All attributes
rf_ref = []
mic = []
path_datasets = "Datasets"
rf_ref = get_score_features_random_forest_classifier("/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, [])
mic = get_score_features("/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, [], 0.0)

import numpy as np
import matplotlib.pyplot as plot
# Get x values of the sine wave
plot.figure(figsize = (20, 8))

# data to be plotted
x = np.arange(0, len(mic))
y = mic

# Plot a sine wave using time and amplitude obtained for the sine wave
plot.plot(x, y, 'o')

# Give a title for the sine wave plot
plot.title('MIC')

# Give x axis label for the sine wave plot
plot.xlabel('Feature indexes')

# Give y axis label for the sine wave plot
plot.ylabel('MIC results')
plot.grid(True, which='both')
plot.axhline(y=0, color='k')
plot.show()


plot.figure(figsize = (20, 8))
# data to be plotted
x = np.arange(0, len(rf_ref))
y = rf_ref

# Plot a sine wave using time and amplitude obtained for the sine wave
plot.plot(x, y, 'o')

# Give a title for the sine wave plot
plot.title('RF-RFE')

# Give x axis label for the sine wave plot
plot.xlabel('Feature indexes')

# Give y axis label for the sine wave plot
plot.ylabel('RF-RFE results')
plot.grid(True, which='both')
plot.axhline(y=0, color='k')
plot.show()

# Decision
# creating a DataFrame
dict = {'Features_col_name' : features_col_name,
        'RFE' : rf_ref,
        'MIC' : mic,
}
df = pd.DataFrame(dict)
filtered_df = df
display(filtered_df)

# motion_model_random_forest = train_random_forest_fire('Datasets', [])
# test_random_forest_fire(motion_model_random_forest, [])
def generate_remove_array(remove_list):
  all_features = [
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
    11,	12,	13,	14,	15,	16,	17,	18,	19,	20,
    21, 22, 23, 24,	25,	26,	27,	28,	29,	30,
    31,	32,	33,	34,	35,	36,	37,	38,	39,	40,
    41,	42, 43,	44,	45,	46,	47,	48,	49,	50,
    51,	52,	53,	54,	55,	56,	57,	58,	59,	60,
    61,	62,	63,	64,	65,	66,	67,	68,	69,	70,
    71,	72,	73, 74, 75, 76, 77, 78, 79, 80,
    81, 82, 83, 84, 85, 86, 87, 88]
  for ele in remove_list:
    all_features.remove(ele)
  return all_features


selected_features_motion = []
selected_features_luminance = []
selected_features_colours_R = []
selected_features_colours_G = []
selected_features_colours_B = []

# Motion
motions_df = filtered_df[filtered_df.Features_col_name.isin([
  "iVecCoun", "dRadius", "dCohIndex", "vardRadius", "vardCohIndex", "dCos", "dSin"])]
display(motions_df)
print('selected features', motions_df.index)
selected_features_motion = motions_df.index.values

# Luminance
luminance_df = filtered_df[filtered_df.Features_col_name.isin(["d_luminance"])]
display(luminance_df)
print('selected features', luminance_df.index)
selected_features_luminance = luminance_df.index.values

# Colours_R
colours_R_df = filtered_df[filtered_df.Features_col_name.isin([
            "ia5R_v0", "ia5R_v1", "ia5R_v2", "ia5R_v3", "ia5R_v4",
            "ia5R_f0", "ia5R_f1", "ia5R_f2", "ia5R_f3", "ia5R_f4"
            ])]
display(colours_R_df)
print('selected features', colours_R_df.index)
selected_features_colours_R = colours_R_df.index.values

# Colours_G
colours_G_df = filtered_df[filtered_df.Features_col_name.isin([
            "ia5G_v0", "ia5G_v1", "ia5G_v2", "ia5G_v3", "ia5G_v4",
            "ia5G_f0", "ia5G_f1", "ia5G_f2", "ia5G_f3", "ia5G_f4",
            ])]
display(colours_G_df)
print('selected features', colours_G_df.index)
selected_features_colours_G = colours_G_df.index.values

# Colours_B
colours_B_df = filtered_df[filtered_df.Features_col_name.isin([
            "ia5B_v0", "ia5B_v1", "ia5B_v2", "ia5B_v3", "ia5B_v4",
            "ia5B_f0", "ia5B_f1", "ia5B_f2", "ia5B_f3", "ia5B_f4",
            ])]
display(colours_B_df)
print('selected features', colours_B_df.index)
selected_features_colours_B = colours_B_df.index.values

# Commented out IPython magic to ensure Python compatibility.
import os

# linear algebra
import numpy as np 

# data processing
import pandas as pd 

# data visualization
import seaborn as sns
# %matplotlib inline
from matplotlib import pyplot as plt
from matplotlib import style

# Algorithms
from sklearn import linear_model
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier

# https://towardsdatascience.com/fit-vs-predict-vs-fit-predict-in-python-scikit-learn-f15a34a8d39f
path_datasets = "Datasets"
def train_random_forest_fire(remove):
    data_train = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, remove=remove)
    train_data, train_label = get_train_data(data_train)
    random_forest_model = RandomForestClassifier(
        n_jobs=-1, max_depth=11, 
        n_estimators=50, min_samples_leaf=1)
    # Split train and test
    random_forest_model.fit(train_data, train_label)
    return random_forest_model

def train_decision_tree_fire(remove):
    data_train = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, remove=remove)
    train_data, train_label = get_train_data(data_train)
    decision_tree_model = DecisionTreeClassifier()
    decision_tree_model.fit(train_data, train_label)  
    return decision_tree_model

def train_KNN(remove):
    data_train = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, remove=remove)
    train_data, train_label = get_train_data(data_train)
    knn_model = KNeighborsClassifier(n_neighbors = 3) 
    knn_model.fit(train_data, train_label)
    return knn_model

def train_logistic_regression(remove):
    data_train = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, remove=remove)
    train_data, train_label = get_train_data(data_train)
    logreg_model = LogisticRegression()
    logreg_model.fit(train_data, train_label)
    return logreg_model

def train_gaussian_naive_bayes(remove):
    data_train = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, remove=remove)
    train_data, train_label = get_train_data(data_train)
    gaussian_model = GaussianNB()
    gaussian_model.fit(train_data, train_label)
    return gaussian_model

def train_neural_network_mlpclassifier(remove):
  data_train = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/" + path_datasets, remove=remove)
  train_data, train_label = get_train_data(data_train)
  neural_network_mlp_model = MLPClassifier(random_state=1, max_iter=300)
  neural_network_mlp_model.fit(train_data, train_label)
  return neural_network_mlp_model


motion_model_random_forest_all = train_random_forest_fire([])

def generate_remove_array(remove_list):
  all_features = [
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
    11,	12,	13,	14,	15,	16,	17,	18,	19,	20,
    21, 22, 23, 24,	25,	26,	27,	28,	29,	30,
    31,	32,	33,	34,	35,	36,	37,	38,	39,	40,
    41,	42, 43,	44,	45,	46,	47,	48,	49,	50,
    51,	52,	53,	54,	55,	56,	57,	58,	59,	60,
    61,	62,	63,	64,	65,	66,	67,	68,	69,	70,
    71,	72,	73, 74, 75, 76, 77, 78, 79, 80,
    81, 82, 83, 84, 85, 86, 87, 88]
  for ele in remove_list:
    all_features.remove(ele)
  return all_features

# Use Remove to split up motion, luminance, and RGB
# Get attributes for motion by removing others attribute.
# Motion attributes 0,	1,	2,	3,	4, 22,	23

"""
remove_not_motion = [
                    5, 6,	7,	8,	9,	10,
          11,	12,	13,	14,	15,	16,	17,	18,	19,	20,
          21, 24,	25,	26,	27,	28,	29,	30,
          31,	32,	33,	34,	35,	36,	37,	38,	39,	40,
          41,	42, 43,	44,	45,	46,	47,	48,	49,	50,
          51,	52,	53,	54,	55,	56,	57,	58,	59,	60,
          61,	62,	63,	64,	65,	66,	67,	68,	69,	70,
          71,	72,	73, 74, 75, 76, 77, 78, 79, 80,
          81, 82, 83, 84, 85, 86, 87, 88]
"""

remove_not_motion = generate_remove_array(selected_features_motion)
print(remove_not_motion)
motion_model_random_forest = train_random_forest_fire(remove_not_motion)

# Get attributes for luminance by removing others attribute.
# luminance attribute: 43.
# ***** opaque, transparency.
"""
remove_not_luminance = [
          0, 1,	2,	3,	4, 5, 6,	7,	8,	9,	10,	
          11,	12,	13,	14,	15,	16,	17,	18,	19,	20,	
          21, 22,	23, 24,	25,	26,	27,	28,	29,	30,	
          31,	32,	33,	34,	35,	36,	37,	38,	39,	40,	
          41,	42,	44,	45,	46,	47,	48,	49,	50,	
          51,	52,	53,	54,	55,	56,	57,	58,	59,	60,	
          61,	62,	63,	64,	65,	66,	67,	68,	69,	70,	
          71,	72,	73, 74, 75, 76, 77, 78, 79, 80, 
          81, 82, 83, 84, 85, 86, 87, 88]
"""
remove_not_luminance = generate_remove_array(selected_features_luminance)
print(remove_not_luminance)
luminance_model_random_forest = train_random_forest_fire(remove_not_luminance)

# Get attributes for R colour.
# colour attribute: 44	45	46	47	48	49	50	51	52	53
"""
remove_not_colour_R = [
          0, 1,	2,	3,	4, 5, 6,	7,	8,	9,	10,	
          11,	12,	13,	14,	15,	16,	17,	18,	19,	20,	
          21, 22,	23, 24,	25,	26,	27,	28,	29,	30,	
          31,	32,	33,	34,	35,	36,	37,	38,	39,	40,	
          41,	42,	43, 54,	55,	56,	57,	58,	59,	60,	
          61,	62,	63,	64,	65,	66,	67,	68,	69,	70,	
          71,	72,	73,	74,	75,	76,	77,	78,	79,	80,	
          81,	82,	83,	84,	85,	86,	87,	88]
"""
remove_not_colour_R = generate_remove_array(selected_features_colours_R)
print(remove_not_colour_R)
colour_R_model_random_forest = train_random_forest_fire(remove_not_colour_R)

# Get attributes for G colour.
# colour attribute: 59	60	61	62	63	64	65	66	67	68
"""
remove_not_colour_G = [
          0, 1,	2,	3,	4, 5, 6,	7,	8,	9,	10,
          11,	12,	13,	14,	15,	16,	17,	18,	19,	20,	
          21, 22,	23, 24,	25,	26,	27,	28,	29,	30,	
          31,	32,	33,	34,	35,	36,	37,	38,	39,	40,	
          41,	42,	43, 44, 45, 46, 47, 48, 49, 50,
          51, 52, 53, 54, 55, 56, 57, 58, 69,	70,
          71,	72,	73,	74,	75,	76,	77,	78,	79,	80,	
          81,	82,	83,	84,	85,	86,	87,	88]
"""
remove_not_colour_G = generate_remove_array(selected_features_colours_G)
print(remove_not_colour_G)
colour_G_model_random_forest = train_random_forest_fire(remove_not_colour_G)

# Get attributes for B colour.
# colour attribute: 74	75	76	77	78	79	80	81	82	83
"""
remove_not_colour_B = [
          0, 1,	2,	3,	4, 5, 6,	7,	8,	9,	10,	
          11,	12,	13,	14,	15,	16,	17,	18,	19,	20,	
          21, 22,	23, 24,	25,	26,	27,	28,	29,	30,	
          31,	32,	33,	34,	35,	36,	37,	38,	39,	40,	
          41,	42,	43, 44, 45, 46, 47, 48, 49, 50,
          51, 52, 53, 54, 55, 56, 57, 58, 59, 60,
          61, 62, 63, 64, 65, 66, 67, 68, 69, 70,
          71,	72,	73,	84,	85,	86,	87,	88]
"""
remove_not_colour_B = generate_remove_array(selected_features_colours_B)
print(remove_not_colour_B)
colour_B_model_random_forest = train_random_forest_fire(remove_not_colour_B)
print("Training done!")

from tabulate import tabulate
import math

def sigmoid(x):
  return 1 / (1 + math.exp(-x))

def is_fire(model, remove, name="", threshold = 80):
    # SB_Vt = "SB_19_Vt_0.1"
    # Comparison purple fire and smoke.
    # data_test_fire = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/Dataset_test_fire_" + SB_Vt, remove=remove)
    # data_test_fire = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/Dataset_test_not_fire_" + SB_Vt, remove=remove)
    
    # Test with blue fire.
    footage_name = "footage01-015"
    # Test with orange fire.
    # footage_name = "footage01-010"
    # Test with non fire.
    # footage_name = "footage02-023"

    # footage_name = "footage01-014"
    # footage_name = "footage00-008"
    # footage_name = "footage02-006"

    data_test_fire = get_Data(dir_name="/content/gdrive/MyDrive/Tensorflow/second/Test_datasets/" + footage_name, remove=remove)
    test_data, test_label = get_test_data(data_test_fire)
    Y_prediction = model.predict(test_data)
    isFire = True if ((100 * np.count_nonzero(Y_prediction == 1) / len(Y_prediction)) > threshold) else False
    percentage_fire = (100 * np.count_nonzero(Y_prediction == 1) / len(Y_prediction))
    percentage_not_fire = (100 * np.count_nonzero(Y_prediction == 0) / len(Y_prediction))
    df = pd.DataFrame({
      name : [str(percentage_not_fire) + " %", str(percentage_fire) + " %"],
    })
    print(tabulate(df, headers='keys', tablefmt='psql'))
    return isFire, percentage_fire, percentage_not_fire;

def print_report(nameOfReport, motion_model, luminance_model, colour_R_model, colour_G_model, colour_B_model, 
                 remove_not_motion, remove_not_luminance, remove_not_colour_R, remove_not_colour_G, remove_not_colour_B):
  print(nameOfReport)
  isMotionOfFire, percentage_fire_motion, percentage_not_fire_motion = is_fire(motion_model, remove_not_motion, "Motion", 80)
  isLuminanceOfFire, percentage_fire_luminance, percentage_not_fire_luminance = is_fire(luminance_model, remove_not_luminance, "Luminance", 50)
  isColourOfFireR, percentage_fire_R, percentage_not_fire_R = is_fire(colour_R_model, remove_not_colour_R, "Red Channel", 80)
  isColourOfFireG, percentage_fire_G, percentage_not_fire_G = is_fire(colour_G_model, remove_not_colour_G, "Green Channel", 20)
  isColourOfFireB, percentage_fire_B, percentage_not_fire_B = is_fire(colour_B_model, remove_not_colour_B, "Blue Channel", 80)

  motion.append(percentage_fire_motion)
  motion.append(percentage_not_fire_motion)
  
  luminance.append(percentage_fire_luminance)
  luminance.append(percentage_not_fire_luminance)
  
  red.append(percentage_fire_R)
  red.append(percentage_not_fire_R)
  
  green.append(percentage_fire_G)
  green.append(percentage_not_fire_G)
  
  blue.append(percentage_fire_B)
  blue.append(percentage_not_fire_B)

  print("IsMotionOfFire fire:", isMotionOfFire)
  print("isLuminanceOfFire fire:", isLuminanceOfFire)
  print("isColouredOfFireR fire:", isColourOfFireR)
  print("isColouredOfFireG fire:", isColourOfFireG)
  print("isColouredOfFireB fire:", isColourOfFireB)
  print("")

motion = []
luminance = []
red = []
green = []
blue = []
all = []

allIsFire, allPercentage_fire, allPercentage_not_fire= is_fire(motion_model_random_forest_all, [], "All", 0)

print_report("Random forest",
             motion_model_random_forest, 
             luminance_model_random_forest, 
             colour_R_model_random_forest, 
             colour_G_model_random_forest,
             colour_B_model_random_forest,
             remove_not_motion,
             remove_not_luminance,
             remove_not_colour_R,
             remove_not_colour_G,
             remove_not_colour_B)

import numpy as np
import matplotlib.pyplot as plt
 
# set width of bar
barWidth = 0.25
fig = plt.subplots(figsize =(20, 8))
 
# set height of bar
Fire = [motion[0], luminance[0], red[0], green[0], blue[0]]
Not_Fire = [motion[1], luminance[1], red[1], green[1], blue[1]]

# Set position of bar on X axis
br1 = np.arange(len(Fire))
br2 = [x + barWidth for x in br1]

# Make the plot
plt.bar(br1, Fire, color ='red', width = barWidth,
        edgecolor ='grey', label ='Fire')
plt.bar(br2, Not_Fire, color ='green', width = barWidth,
        edgecolor ='grey', label ='Not Fire')
 
# Adding Xticks
plt.xlabel('', fontweight ='bold', fontsize = 15)
plt.ylabel('', fontweight ='bold', fontsize = 15)
plt.xticks([r + 0.12 for r in range(len(Fire))],
        ['Motion', 'Luminance', 'Red', 'Green', 'Blue'])
 
plt.legend()
plt.show()

# ALL features
import numpy as np
import matplotlib.pyplot as plt
 
# set width of bar
barWidth = 0.5
fig = plt.subplots(figsize =(5, 8))
 
# set height of bar
Fire = [allPercentage_fire]
Not_Fire = [allPercentage_not_fire]

# Set position of bar on X axis
br1 = np.arange(len(Fire))
br2 = [x + barWidth for x in br1]

# Make the plot
plt.bar(br1, Fire, color ='red', width = barWidth,
        edgecolor ='grey', label ='Fire')
plt.bar(br2, Not_Fire, color ='green', width = barWidth,
        edgecolor ='grey', label ='Not Fire')
 
# Adding Xticks
plt.xlabel('', fontweight ='bold', fontsize = 15)
plt.ylabel('', fontweight ='bold', fontsize = 15)
plt.xticks([r + 0.25 for r in range(len(Fire))],
        ['All 89 Features'])
 
plt.legend()
plt.show()